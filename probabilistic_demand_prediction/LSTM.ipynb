{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1a7646-7dce-4018-857f-7155ce783083",
   "metadata": {},
   "source": [
    "### Training Monte Carlo LSTM (MC-LSTM)\n",
    "**Authors:** Akash Mahajan, Van-Hai Bui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92437ee7-0730-4392-9de2-af3d358f84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Softplus\n",
    "from torch.optim import Adam\n",
    "from torch.nn import GaussianNLLLoss\n",
    "\n",
    "from utils.Datasets import TimeSeriesDataset\n",
    "from utils.Network import NetConfig, TrainConfig\n",
    "from utils.Priors import GaussianPrior, Prior\n",
    "from utils.nn.LSTM import LSTM\n",
    "from utils.Network import LSTMTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aef5e4-a541-485b-93f7-eb838dfd56e4",
   "metadata": {},
   "source": [
    "#### 1. Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d582912-75ab-4536-93ba-4d9d7160f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"output/data.csv\", parse_dates=True)\n",
    "\n",
    "# setting the time index\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434685b-7ed0-496c-8c62-9d34e389a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize only the continous feature variables, not categorical variables\n",
    "from utils.data_loader import standardize\n",
    "\n",
    "x_std_features = ['Interior_Zone_temp_mean', 'solar_radiation', 'relative_humidity', 'air_temperature', 'wind_speed']\n",
    "std_features, _, _ = standardize(df[x_std_features])\n",
    "\n",
    "df[x_std_features] = std_features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25644335-94fd-4c37-8000-1c07035497d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two and half years of data for training and half years of data for testing \n",
    "start_train = \"2018-01-01\"\n",
    "end_train = \"2020-06-30\"\n",
    "start_test = \"2020-07-01\"\n",
    "end_test = \"2020-12-31\"\n",
    "\n",
    "# Demand\n",
    "target = \"elec_kW\"\n",
    "y_columns = [target]\n",
    "\n",
    "x_columns = [c for c in df.columns if c != target]\n",
    "print(\"Targets:\", y_columns)\n",
    "print(\"Input features:\", x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627b6b9-b881-4dbc-a98e-91460330d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_sequence_length = 24\n",
    "test_idx = df[start_test:end_test].index[historical_sequence_length:].to_numpy()\n",
    "\n",
    "# Save test index for later use\n",
    "np.save(\"output/test_index.npy\", test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332723d-befd-4a91-ad54-60b2fc5dca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training and testing datatset (Future development: validation data)\n",
    "x_train = df[x_columns][start_train:end_train].values\n",
    "y_train = df[y_columns][start_train:end_train].values\n",
    "x_test = df[x_columns][start_test:end_test].values\n",
    "y_test = df[y_columns][start_test:end_test].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aed765-fc52-4d29-b65c-ecb0fd54e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe6820-08f7-4436-a251-1b665fa5eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "sequential = True\n",
    "batch_size = 64\n",
    "historical_sequence_length = 24\n",
    "\n",
    "train_data = TimeSeriesDataset(x_train, y_train, historical_sequence_length, sequential)\n",
    "# train_stats = train_data.transform()\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, drop_last=False, shuffle=False, num_workers=0)\n",
    "\n",
    "test_data = TimeSeriesDataset(x_test, y_test, historical_sequence_length, sequential)\n",
    "# test_stats = test_data.transform()\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, drop_last=False, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf56df-75eb-4133-a1c3-18ca130db224",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0dc126-6e58-43f9-b5e3-05f5cc4c04d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_units = x_train.shape[-1] if sequential else x_train.shape[-1] * historical_sequence_length\n",
    "output_units = y_train.shape[-1]\n",
    "\n",
    "# prior = GaussianPrior(mean=0, spread=0.1)\n",
    "net_config = NetConfig(None, input_units, output_units, output_activation=Softplus(), model_name=\"LSTM\")\n",
    "\n",
    "net_config.drop_probability = 0.5   # Special parameters for LSTM\n",
    "net_config.stacked_layers = 2\n",
    "\n",
    "print(\"Model input units:\", input_units)\n",
    "print(\"Model output units:\", output_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef2ff4-9485-4c7a-8b28-ce5401e0a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "layer_units = [512, 512, 128]\n",
    "\n",
    "for n_units in layer_units:\n",
    "    net_config.add_layer(n_units)\n",
    "\n",
    "model = LSTM(net_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb38f1-ba18-4418-808b-5d1113c2d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional training parameters\n",
    "epochs = 2000\n",
    "learning_rate = 1e-4  # 0.001\n",
    "\n",
    "target_folder = f\"LSTM_elec_{epochs}_{learning_rate}_{batch_size}\"\n",
    "\n",
    "loss = GaussianNLLLoss(full=True, reduction='sum')\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "\n",
    "train_config = TrainConfig(batch_size=batch_size, epochs=epochs, optimizer=optimizer, \n",
    "                           learning_rate=learning_rate, loss=loss, save_folder=target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fed228-ee2a-49a8-954d-0d3e379f5990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer = LSTMTrainer(train_loader, None, model, train_config)\n",
    "train_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2994b7-a848-4779-9e06-5c9b00330818",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history.to_file(model_name=target_folder, config=train_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
